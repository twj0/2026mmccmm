# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a COMAP MCM/ICM 2026 Problem C repository for analyzing Dancing With The Stars (DWTS) data across seasons 1-34. The project uses statistical modeling and simulation to:
- Estimate fan voting patterns from elimination data (Q1)
- Compare voting mechanisms via counterfactual simulation (Q2)
- Analyze impacts of celebrity attributes on outcomes (Q3)
- Design and evaluate alternative voting systems (Q4)

## Development Environment

**Python Version**: 3.11 (see `.python-version`)
**Package Manager**: `uv` (not pip)

### Setup Commands

```bash
# Create/sync environment (default dev dependencies)
uv sync

# Include all optional groups
uv sync --all-groups

# Include specific optional groups
uv sync --group dl      # PyTorch with CUDA 12.4
uv sync --group web     # Web scraping (only if data policy allows)
uv sync --group ml      # XGBoost
uv sync --group opt     # Optimization (cvxpy, pulp)
uv sync --group notebook # Jupyter
```

### Running the Pipeline

```bash
# Main reproducible pipeline (Q0-Q4)
uv run python run_all.py

# Include showcase/appendix experiments
uv run python run_all.py --showcase
```

### Testing and Linting

```bash
# Run linter
uv run ruff check .

# Run tests
uv run pytest
```

## Architecture

### Directory Structure

- `data/raw/` - Original problem attachments (read-only)
- `data/processed/` - Cleaned datasets generated by Q0 pipeline
- `src/mcm2026/` - Reusable code organized by function:
  - `core/` - Path management and project conventions
  - `data/` - Data I/O and auditing utilities
  - `pipelines/` - Main reproducible pipelines (Q0-Q4)
  - `pipelines/showcase/` - Appendix-only experiments (do not modify mainline outputs)
- `outputs/` - Generated artifacts for the paper:
  - `figures/` - PNG/PDF visualizations
  - `tables/` - CSV/TeX tables
  - `predictions/` - Model predictions with uncertainty
- `paper/` - LaTeX paper (template from `examples/MCM-Latex-template`)
- `docs/` - Internal documentation:
  - `spec/` - Task specifications and architecture
  - `project_document/` - Modeling approach for each question

### Pipeline Flow

The `run_all.py` script orchestrates the entire analysis:

1. **Q0** (`mcm2026c_q0_build_weekly_panel.py`) - Build canonical weekly panel dataset
   - Outputs: `data/processed/dwts_weekly_panel.csv`, `data/processed/dwts_season_features.csv`
2. **Q1** (`mcm2026c_q1_smc_fan_vote.py`) - Estimate fan vote share/index via Sequential Monte Carlo
   - Outputs: `outputs/predictions/mcm2026c_q1_fan_vote_posterior_summary.csv`
3. **Q2** (`mcm2026c_q2_counterfactual_simulation.py`) - Compare Rank vs Percent mechanisms
   - Outputs: `outputs/tables/mcm2026c_q2_mechanism_comparison.csv`
4. **Q3** (`mcm2026c_q3_mixed_effects_impacts.py`) - Analyze celebrity/pro dancer impacts
   - Outputs: `outputs/tables/mcm2026c_q3_impact_analysis_coeffs.csv`
5. **Q4** (`mcm2026c_q4_design_space_eval.py`) - Evaluate alternative voting systems
   - Outputs: `outputs/tables/mcm2026c_q4_new_system_metrics.csv`

### Showcase Module

The `showcase/` subdirectory contains appendix-only experiments:
- Machine learning baselines (LogReg, MLP) for comparison
- Sensitivity analyses and grid searches
- **Critical**: Showcase outputs go to `outputs/tables/showcase/` and never modify mainline artifacts
- Enable via `--showcase` flag or `src/mcm2026/config/config.yaml`

## Configuration

Main configuration file: `src/mcm2026/config/config.yaml`

Key parameters:
- `dwts.q1.alpha` - Judge vs fan weight (default: 0.5 = 50-50)
- `dwts.q1.tau` - Softmax temperature for elimination likelihood (default: 0.03)
- `dwts.q1.prior_draws_m` - Number of prior samples (default: 2000)
- `dwts.q1.posterior_resample_r` - Number of posterior samples (default: 500)
- `showcase.enabled` - Enable/disable showcase experiments (default: false)

## Key Design Principles

### Data Policy
- **Main pipeline does NOT depend on external popularity data** (Google Trends, Wikipedia pageviews)
- External data may be used for audit/appendix discussion only
- All mainline inputs come from the provided `2026_MCM_Problem_C_Data.csv`

### Reproducibility
- All outputs are deterministically generated from `run_all.py`
- Use seeds from config for stochastic methods
- No manual edits of generated artifacts

### Single Source of Truth
- `data/processed/dwts_weekly_panel.csv` is the canonical dataset
- All Q1-Q4 pipelines read from this processed data
- Grain: `(season, week, celebrity_name)`

### Uncertainty Quantification
- Q1 outputs are fan vote **share/index** (not absolute counts) with uncertainty intervals
- Methods emphasize interpretability over black-box accuracy
- Bootstrap/resampling for robustness analysis

### Naming Conventions
- Pipeline scripts: `mcm2026c_q<N>_<description>.py`
- Output files: `mcm2026c_q<N>_<artifact_type>.csv`
- Showcase outputs: `mcm2026c_q<N>_<method>_<artifact>.csv` in `showcase/` subdirectory

## Common Tasks

### Adding a New Pipeline

1. Create script in `src/mcm2026/pipelines/` following naming convention
2. Define a `run()` function that returns a dataclass with output paths
3. Import and call from `run_all.py` in the appropriate sequence
4. Ensure outputs go to `outputs/` subdirectories

### Modifying Configuration

Edit `src/mcm2026/config/config.yaml` and rerun `run_all.py`. The config uses extensive comments explaining each parameter's meaning and typical ranges.

### Running Individual Pipelines

```bash
# Run as module
uv run python -m mcm2026.pipelines.mcm2026c_q1_smc_fan_vote

# Or import in Python
from mcm2026.pipelines.mcm2026c_q1_smc_fan_vote import run
output = run()
```

### Adding Showcase Experiments

1. Create script in `src/mcm2026/pipelines/showcase/`
2. Write outputs to `outputs/tables/showcase/` or `outputs/figures/showcase/`
3. Add configuration to `config.yaml` under `showcase.q<N>`
4. Import conditionally in `run_all.py` when `--showcase` flag is present

## Important Notes

### Path Management
Use `mcm2026.core.paths` module for all path operations:
```python
from mcm2026.core import paths
paths.raw_data_dir()      # data/raw/
paths.processed_data_dir() # data/processed/
paths.tables_dir()        # outputs/tables/
paths.figures_dir()       # outputs/figures/
paths.predictions_dir()   # outputs/predictions/
```

### Data I/O
Use `mcm2026.data.io` for consistent reading/writing:
```python
from mcm2026.data import io
df = io.read_table(path)  # Auto-detects CSV/TSV/Excel/Parquet
io.write_csv(df, path)
```

### Auditing
Use `mcm2026.data.audit` for data quality checks:
```python
from mcm2026.data import audit
summary = audit.audit_summary_dict(df)
col_audit = audit.audit_columns(df)
```

## Documentation References

- **Project structure**: `docs/project_structure.md`
- **Task specification**: `docs/spec/task.md`
- **Architecture**: `docs/spec/architecture.md`
- **Showcase module**: `docs/project_document/showcase.md`
- **MCM workflow**: `.windsurf/workflows/mcm.md`
- **Paper draft**: `paper/draft.md` (Chinese, Markdown, no images)

## Contest-Specific Constraints

This is a mathematical modeling contest submission with specific requirements:
- Emphasis on interpretability and uncertainty quantification
- Methods must be justified and validated
- Results must include sensitivity analysis
- Paper includes 1-page Summary Sheet and 1-2 page Memo/Letter
- LaTeX template from `examples/MCM-Latex-template`
